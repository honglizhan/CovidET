{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b5c792",
   "metadata": {},
   "source": [
    "Using the PSAW wrapper for Pushshift API to retrieve original posts in CovidET\n",
    "\n",
    "Created on Wed Oct 26, 2022\n",
    "\n",
    "@author: Sarah Seraj, Hongli Zhan, John Henry Cruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db2c7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import json\n",
    "import string\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from time import sleep\n",
    "from psaw import PushshiftAPI\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212a3f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f995de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1883\n"
     ]
    }
   ],
   "source": [
    "# Extract reddit ids\n",
    "dataset_df = pd.read_json(\"./data/CovidET_anonymized.json\", orient=\"index\")\n",
    "reddit_ids = list(dataset_df[\"Reddit ID\"])\n",
    "print (len(reddit_ids))\n",
    "reddit_ids_chunks = chunks(reddit_ids, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23593b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDIT: List subreddits separated by commas\n",
    "subreddit_name = ['COVID19_support']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63697ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580536800\n",
      "1646114400\n"
     ]
    }
   ],
   "source": [
    "#EDIT: beginning & end dates of the period for which you want data\n",
    "start_epoch=int(dt.datetime(2020, 2, 1).timestamp())\n",
    "end_epoch=int(dt.datetime(2022, 3, 1).timestamp())\n",
    "print (start_epoch)\n",
    "print (end_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d4a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()\n",
    "cache = []\n",
    "max_response_cache = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b107d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:192: UserWarning: Got non 200 code 429\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n"
     ]
    }
   ],
   "source": [
    "for reddit_id_chunk in reddit_ids_chunks:\n",
    "    try:\n",
    "        for name in subreddit_name:\n",
    "            gen = api.search_submissions(ids=reddit_id_chunk, subreddit=name,\n",
    "                                         filter=['author', 'created_utc', 'subreddit', 'selftext',\n",
    "                                                 'id','parent_id', 'score', 'author_flair_css_class',\n",
    "                                                 'author_flair_text', 'metadata'], after=start_epoch, before=end_epoch)\n",
    "            for c in gen:\n",
    "                cache.append(c)\n",
    "\n",
    "            # Omit this test to actually return all results. Could take a while\n",
    "            if len(cache) >= max_response_cache:\n",
    "                break\n",
    "\n",
    "    except ConnectionAbortedError:\n",
    "        #sleep(20)\n",
    "        print(\"ConnectionAbortedError occurred\")\n",
    "    except:\n",
    "        #print(\"other exception occurred\")\n",
    "        #sleep(60)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c35facfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1883\n"
     ]
    }
   ],
   "source": [
    "cleaned_cache = [c.d_ for c in cache]\n",
    "\n",
    "df = pd.DataFrame(cleaned_cache)\n",
    "df = df.drop(columns=\"author_flair_text\")\n",
    "df = df.drop(columns=\"created\")\n",
    "df = df.drop(columns=\"score\")\n",
    "print (len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "57352aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ibalbalu</td>\n",
       "      <td>1624481483</td>\n",
       "      <td>o6lpwn</td>\n",
       "      <td>I don’t even know how to speak of this grief. ...</td>\n",
       "      <td>COVID19_support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PKNinja69</td>\n",
       "      <td>1624639614</td>\n",
       "      <td>o7riyw</td>\n",
       "      <td>Hello,\\n\\nI am about 19 and it's been about 2 ...</td>\n",
       "      <td>COVID19_support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hotzendorf1918</td>\n",
       "      <td>1624619535</td>\n",
       "      <td>o7lkru</td>\n",
       "      <td>Recently, the Israeli government reinstituted ...</td>\n",
       "      <td>COVID19_support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tp151234</td>\n",
       "      <td>1624656076</td>\n",
       "      <td>o7wv0a</td>\n",
       "      <td>This makes me really just not want to go out a...</td>\n",
       "      <td>COVID19_support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mikoaimi</td>\n",
       "      <td>1624675779</td>\n",
       "      <td>o82alq</td>\n",
       "      <td>I have a question about the delta variant. I’v...</td>\n",
       "      <td>COVID19_support</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author  created_utc      id  \\\n",
       "0        ibalbalu   1624481483  o6lpwn   \n",
       "1       PKNinja69   1624639614  o7riyw   \n",
       "2  Hotzendorf1918   1624619535  o7lkru   \n",
       "3        tp151234   1624656076  o7wv0a   \n",
       "4        Mikoaimi   1624675779  o82alq   \n",
       "\n",
       "                                            selftext        subreddit  \n",
       "0  I don’t even know how to speak of this grief. ...  COVID19_support  \n",
       "1  Hello,\\n\\nI am about 19 and it's been about 2 ...  COVID19_support  \n",
       "2  Recently, the Israeli government reinstituted ...  COVID19_support  \n",
       "3  This makes me really just not want to go out a...  COVID19_support  \n",
       "4  I have a question about the delta variant. I’v...  COVID19_support  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "931251d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selftext_list = df['selftext'].tolist()\n",
    "selftext_length = []\n",
    "punctuations = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d1ea7fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(selftext_list)):\n",
    "    file_content = selftext_list[i]\n",
    "    file_content = file_content.encode('ascii', 'ignore').decode('ascii')\n",
    "    file_content = re.sub(\"\\s+\",\" \", file_content)\n",
    "    selftext_list[i] = file_content\n",
    "    \n",
    "    file_content_no_punct = re.sub(r'(?<=[.,!?:])(?=[^\\s])', r' ', file_content)\n",
    "    file_content_no_punct = re.sub(r'\\s([?.!,:\"](?:\\s|$))', r'\\1', file_content_no_punct)\n",
    "    selftext_tokenized = word_tokenize(file_content_no_punct)\n",
    "    selftext_tokenized = [i for i in selftext_tokenized if i not in punctuations]\n",
    "    selftext_length.append(len(selftext_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "db7d80b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext_cleaned'] = selftext_list\n",
    "df['selftext_length'] = selftext_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8f32a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext_cleaned'] = df['selftext_cleaned'].str.replace(r'http\\S+', '<URL>', regex=True).str.strip()\n",
    "df['selftext_cleaned'] = df['selftext_cleaned'].str.replace(\n",
    "    r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|'''\\\n",
    "    '''(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', '<URL>',\n",
    "    regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3cc25661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anonymize\n",
    "\n",
    "ORG_lst = [\n",
    "    'Pfizer',\n",
    "    'Pfizers',\n",
    "    'J&J',\n",
    "    'Johnson & Johnson',\n",
    "    \"Johnson & Johnson's\",\n",
    "    'AstraZeneca',\n",
    "    'SINOVAC',\n",
    "    'Ivermectin',\n",
    "    'Novavax',\n",
    "    'Astrazeneca',\n",
    "    'the New York Times',\n",
    "    'the NY Times',\n",
    "    'CNBC',\n",
    "    'NBC News',\n",
    "    'Gottlieb',\n",
    "    'Royal Mail',\n",
    "    'the Mayo Clinic',\n",
    "    'People.com',\n",
    "    'Fox News',\n",
    "    'Roche',\n",
    "    'QuickVue',\n",
    "    'Amtrak',\n",
    "    \"Moderma\",\n",
    "    'Moderna',\n",
    "    'regencov',\n",
    "]\n",
    "\n",
    "PERSON_lst = [\n",
    "    'Trump',\n",
    "    'Fauci',\n",
    "    'Modi',\n",
    "    'Cyrus Shahpar',\n",
    "    \"Cyrus Shahpar's\",\n",
    "    'Vin Gupta',\n",
    "    'Anna',\n",
    "    'Ostenholm',\n",
    "    'Osterholm',\n",
    "    'Aaron Astor',\n",
    "    'Steve',\n",
    "    'Janssen',\n",
    "    'jiu jitsu',\n",
    "    'Jiu Jitsu',\n",
    "    'Biden',\n",
    "    'Astra Zeneca',\n",
    "    'Zedd',\n",
    "    'Alex Jones',\n",
    "    'Bill de Blasio',\n",
    "    'Angier',\n",
    "    'Laurel Bristow',\n",
    "    'Laurel Bastrow',\n",
    "    'Jessica Wildfire',\n",
    "    'Herman Cain',\n",
    "    'JTurner',\n",
    "    'Hotez',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a1e4765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ORG_lst:\n",
    "    df['selftext_cleaned'] = df['selftext_cleaned'].str.replace(i, '<ORG>', regex=False).str.strip()\n",
    "for i in PERSON_lst:\n",
    "    df['selftext_cleaned'] = df['selftext_cleaned'].str.replace(i, '<PERSON>', regex=False).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "64fc980f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext_cleaned</th>\n",
       "      <th>selftext_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ibalbalu</td>\n",
       "      <td>1624481483</td>\n",
       "      <td>o6lpwn</td>\n",
       "      <td>COVID19_support</td>\n",
       "      <td>I dont even know how to speak of this grief. I...</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PKNinja69</td>\n",
       "      <td>1624639614</td>\n",
       "      <td>o7riyw</td>\n",
       "      <td>COVID19_support</td>\n",
       "      <td>Hello, I am about 19 and it's been about 2 day...</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hotzendorf1918</td>\n",
       "      <td>1624619535</td>\n",
       "      <td>o7lkru</td>\n",
       "      <td>COVID19_support</td>\n",
       "      <td>Recently, the Israeli government reinstituted ...</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tp151234</td>\n",
       "      <td>1624656076</td>\n",
       "      <td>o7wv0a</td>\n",
       "      <td>COVID19_support</td>\n",
       "      <td>This makes me really just not want to go out a...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mikoaimi</td>\n",
       "      <td>1624675779</td>\n",
       "      <td>o82alq</td>\n",
       "      <td>COVID19_support</td>\n",
       "      <td>I have a question about the delta variant. Ive...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>lostmelater</td>\n",
       "      <td>1642353271</td>\n",
       "      <td>s5gelw</td>\n",
       "      <td>COVID19_support</td>\n",
       "      <td>I ate a very large meal Friday, felt really na...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>ConsciousEconomist53</td>\n",
       "      <td>1642004130</td>\n",
       "      <td>s2a0rb</td>\n",
       "      <td>COVID19_support</td>\n",
       "      <td>In my opinion, it shouldn't be forever. When t...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>bivalverights</td>\n",
       "      <td>1642465022</td>\n",
       "      <td>s6jcqk</td>\n",
       "      <td>COVID19_support</td>\n",
       "      <td>I took the above test twice, roughly 24 hours ...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>procrast1natrix</td>\n",
       "      <td>1642477603</td>\n",
       "      <td>s6nr73</td>\n",
       "      <td>COVID19_support</td>\n",
       "      <td>Anybody want to read about something happy abo...</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>Dave_W333</td>\n",
       "      <td>1642645865</td>\n",
       "      <td>s87qz4</td>\n",
       "      <td>COVID19_support</td>\n",
       "      <td>I guess it had to happen at some point....I ha...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1883 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    author  created_utc      id        subreddit  \\\n",
       "0                 ibalbalu   1624481483  o6lpwn  COVID19_support   \n",
       "1                PKNinja69   1624639614  o7riyw  COVID19_support   \n",
       "2           Hotzendorf1918   1624619535  o7lkru  COVID19_support   \n",
       "3                 tp151234   1624656076  o7wv0a  COVID19_support   \n",
       "4                 Mikoaimi   1624675779  o82alq  COVID19_support   \n",
       "...                    ...          ...     ...              ...   \n",
       "1878           lostmelater   1642353271  s5gelw  COVID19_support   \n",
       "1879  ConsciousEconomist53   1642004130  s2a0rb  COVID19_support   \n",
       "1880         bivalverights   1642465022  s6jcqk  COVID19_support   \n",
       "1881       procrast1natrix   1642477603  s6nr73  COVID19_support   \n",
       "1882             Dave_W333   1642645865  s87qz4  COVID19_support   \n",
       "\n",
       "                                       selftext_cleaned  selftext_length  \n",
       "0     I dont even know how to speak of this grief. I...              271  \n",
       "1     Hello, I am about 19 and it's been about 2 day...              107  \n",
       "2     Recently, the Israeli government reinstituted ...              203  \n",
       "3     This makes me really just not want to go out a...               97  \n",
       "4     I have a question about the delta variant. Ive...               60  \n",
       "...                                                 ...              ...  \n",
       "1878  I ate a very large meal Friday, felt really na...              101  \n",
       "1879  In my opinion, it shouldn't be forever. When t...               73  \n",
       "1880  I took the above test twice, roughly 24 hours ...               59  \n",
       "1881  Anybody want to read about something happy abo...              152  \n",
       "1882  I guess it had to happen at some point....I ha...               92  \n",
       "\n",
       "[1883 rows x 6 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=\"selftext\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d7e0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
